{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "green-handle",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "large-kruger",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detailed-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 11:52:52.145117: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-19 11:52:52.145135: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  img_to_array, load_img\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import  img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_IMAGES=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-hanging",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "    1.We load our images from the given directory\n",
    "    2.We convert our images to numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset directory\n",
    "direc='C:/Users/2019/Desktop/Studying/Machine Learning/Image_recolorizer/tiny-imagenet-200/train/n01443537/images2' \n",
    "\n",
    "# counter to limit the amount of images we read\n",
    "counter=0\n",
    "\n",
    "images_to_arrays=[]\n",
    "img_input=[]\n",
    "\n",
    "for x in os.listdir(direc):\n",
    "    # we only read the first 'counter' amount of Jpegs\n",
    "    if x.endswith('.JPEG') and counter<10:      \n",
    "        counter+=1\n",
    "        # Generating the corrosponsing path to the picture\n",
    "        path=direc+'/'+x\n",
    "        target_size=(64,64)\n",
    "        # loading images from the path\n",
    "        img_input.append(load_img(path,target_size=target_size))\n",
    "        \n",
    "# Converting all the pictures to numpy arrays       \n",
    "for x in img_input:\n",
    "    #print(img_to_array(x).shape)\n",
    "    images_to_arrays.append(img_to_array(x))          \n",
    "images_to_arrays=np.array(images_to_arrays)\n",
    "# print(images_to_arrays.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-harvard",
   "metadata": {},
   "source": [
    "### Side Functions:\n",
    "    1.We define plotChannels function to assist in plotting the bounds/ranges of each of the channel types\n",
    "    2.We define L_extract to extract the different channels from an image's LAB version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotChannels(images_to_arrays,labels=['r','g','b']):\n",
    "    #going over each label and calculating max/min values\n",
    "    for x,y in enumerate(labels):\n",
    "        mi=np.min(images_to_arrays[:,:,:,x])\n",
    "        ma=np.max(images_to_arrays[:,:,:,x])\n",
    "        print('{}: min={:8.4f}, max={:8.4f}'.format(y,mi,ma))\n",
    "\n",
    "plotChannels(images_to_arrays,labels=['r','g','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_extract(img,dim):\n",
    "    result=np.zeros(img.shape)\n",
    "    # we return the given channel of LAB in rgb and adjust the brightness only on A and B\n",
    "    if dim != 0:\n",
    "        result[:,:,0]=60\n",
    "    result[:,:,x]=img[:,:,dim]\n",
    "    #convert back to rgb to plot\n",
    "    result=lab2rgb(y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-subdivision",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count=1\n",
    "plut=plt.figure(figsize=(12,3*images_to_arrays.shape[0]))\n",
    "for channel in images_to_arrays:\n",
    "    #adding the subplot for the original picture\n",
    "    x=plut.add_subplot(images_to_arrays.shape[0],4,count)\n",
    "    x.imshow(channel/255.0); x.axis('off')\n",
    "    count+=1\n",
    "    \n",
    "    for dim,label in enumerate(['r','g','b']):\n",
    "        #adding the subplot for each channel for the original picture\n",
    "        uni_colored=np.zeros(channel.shape)\n",
    "        #we set each channel excluding the one we want to 0\n",
    "        uni_colored[:,:,dim]=channel[:,:,dim]\n",
    "        x=plut.add_subplot(images_to_arrays.shape[0],4,count)\n",
    "        x.imshow(uni_colored/255.0); x.axis('off')\n",
    "        count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-distance",
   "metadata": {},
   "source": [
    "## Converting RGB to LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_images=images_to_arrays/255.0\n",
    "plotChannels(normalized_images,['r','g','b'])\n",
    "img_arr_lab=rgb2lab(normalized_images)\n",
    "plotChannels(img_arr_lab,['l','a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lab_rgb=np.zeros(img_arr_lab.shape)\n",
    "img_lab_rgb=lab2rgb(img_arr_lab)\n",
    "plotChannels(img_lab_rgb.reshape((1,)+img_lab_rgb.shape),['r','g','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-better",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count=1\n",
    "fig=plt.figure(figsize=(6,3*images_to_arrays.shape[0]))\n",
    "#we enumerate over our original images and images after double conversion to compare the loss\n",
    "for irgb,irgb2 in zip(normalized_images,img_lab_rgb):\n",
    "    #original\n",
    "    x=fig.add_subplot(images_to_arrays.shape[0],2,count)\n",
    "    x.imshow(irgb); x.axis('off')\n",
    "    x.set_title('rgb')\n",
    "    count+=1\n",
    "    #doubly converted\n",
    "    x=fig.add_subplot(images_to_arrays.shape[0],2,count)\n",
    "    x.imshow(irgb2); x.axis('off')\n",
    "    x.set_title('rgb2lab2rgb')\n",
    "    count+=1\n",
    "    \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=1\n",
    "fig=plt.figure(figsize=(13,3*images_to_arrays.shape[0]))\n",
    "#we plot the three channels of the LAB versions of our images\n",
    "for img in img_arr_lab:\n",
    "    #L\n",
    "    x=fig.add_subplot(images_to_arrays.shape[0],3,count)\n",
    "    lab_rgb_dim=L_extract(img,0)\n",
    "    x.imshow(lab_rgb_dim) ; x.axis('off')\n",
    "    x.set_title('L lmao')\n",
    "    count+=1\n",
    "    #A\n",
    "    x=fig.add_subplot(images_to_arrays.shape[0],3,count)\n",
    "    lab_rgb_dim=L_extract(img,1)\n",
    "    x.imshow(lab_rgb_dim) ; x.axis('off')\n",
    "    x.set_title('A')\n",
    "    count+=1\n",
    "    #B\n",
    "    x=fig.add_subplot(images_to_arrays.shape[0],3,count)\n",
    "    lab_rgb_dim=L_extract(img,2)\n",
    "    x.imshow(lab_rgb_dim) ; x.axis('off')\n",
    "    x.set_title('B')\n",
    "    count+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_array=[]\n",
    "A_array=[]\n",
    "B_array=[]\n",
    "#we extract each dimension of the LAB images onto a different array\n",
    "for img in img_arr_lab:\n",
    "    L_array.append(L_extract(img,0))\n",
    "    A_array.append(L_extract(img,1))\n",
    "    B_array.append(L_extract(img,2))\n",
    "\n",
    "#we insert our data into x and y such that x is our gray images (features), y is our A and B images (classes)\n",
    "y=np.hstack((A_array,B_array)).reshape(NUM_OF_IMAGES,2,64,64,3)\n",
    "x=L_array\n",
    "print(LAB_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we split into train and test such that train=80% * overalldata\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=10\n",
    "input_shape=(64,64,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
